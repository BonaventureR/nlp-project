{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sklearn as sk\n",
    "import re # regex\n",
    "import matplotlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "news_df = pd.read_csv('../datasets/news-20k-comments.csv')\n",
    "politics_df = pd.read_csv(\"../datasets/politics-20k-comments.csv\")\n",
    "politicaldiscussion_df = pd.read_csv('../datasets/politicaldiscussion-20k-comments.csv')\n",
    "\n",
    "news_df = news_df.filter(['created_utc', 'body'])\n",
    "politics_df = politics_df.filter(['created_utc', 'body'])\n",
    "politicaldiscussion_df = politicaldiscussion_df.filter(['created_utc', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out deleted comments\n",
    "news_df = news_df[news_df['body'] != \"[deleted]\"]\n",
    "politics_df = politics_df[politics_df['body'] != \"[deleted]\"]\n",
    "politicaldiscussion_df = politicaldiscussion_df[politicaldiscussion_df['body'] != \"[deleted]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean out any urls and and brackets, parenthesis and hyphens, leaving only alphanumeric words\n",
    "url_regex = r\"([--:\\w?@%&+~#=]*\\.[a-z]{2,4}\\/{0,2})((?:[?&](?:\\w+)=(?:\\w+))+|[--:\\w?@%&+~#=]+)?\"\n",
    "special_character_regex = r\"[\\\"'()[\\]]\"\n",
    "\n",
    "news_df['body'] = news_df['body'].astype('str')\n",
    "politics_df['body'] = politics_df['body'].astype('str')\n",
    "politicaldiscussion_df['body'] = politicaldiscussion_df['body'].astype('str')\n",
    "\n",
    "#remove urls, special characters, and replace hyphens with a space\n",
    "news_df['clean'] = news_df['body'].apply(lambda text: text.strip().lower()).apply(lambda text: re.sub(url_regex, '', text)).apply(lambda text: re.sub(special_character_regex, '', text)).apply(lambda text: re.sub(r\"-\", ' ', text))\n",
    "politics_df['clean'] = politics_df['body'].apply(lambda text: text.strip().lower()).apply(lambda text: re.sub(url_regex, '', text)).apply(lambda text: re.sub(special_character_regex, '', text)).apply(lambda text: re.sub(r\"-\", ' ', text))\n",
    "politicaldiscussion_df['clean'] = politicaldiscussion_df['body'].apply(lambda text: text.strip().lower()).apply(lambda text: re.sub(url_regex, '', text)).apply(lambda text: re.sub(special_character_regex, '', text)).apply(lambda text: re.sub(r\"-\", ' ', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "news_df['tokens'] = news_df['clean'].apply(lambda text: re.sub(r\"[.,!?]\",\" \", text)).apply(lambda text: re.sub(r\"[0-9]\", \" \", text)).apply(nltk.wordpunct_tokenize)\n",
    "politics_df['tokens'] = politics_df['clean'].apply(lambda text: re.sub(r\"[.,!?]\",\" \", text)).apply(lambda text: re.sub(r\"[0-9]\", \" \", text)).apply(nltk.wordpunct_tokenize)\n",
    "politicaldiscussion_df['tokens'] = politicaldiscussion_df['clean'].apply(lambda text: re.sub(r\"[.,!?]\",\" \", text)).apply(lambda text: re.sub(r\"[0-9]\", \" \", text)).apply(nltk.wordpunct_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17536 total comments from r/news\n",
      "18857 total comments from r/politics\n",
      "19174 total comments from r/PoliticalDiscussion\n"
     ]
    }
   ],
   "source": [
    "news_df = news_df.reset_index(drop=True)\n",
    "politics_df = politics_df.reset_index(drop=True)\n",
    "politicaldiscussion_df = politicaldiscussion_df.reset_index(drop=True)\n",
    "print(len(news_df), \"total comments from r/news\")\n",
    "print(len(politics_df), \"total comments from r/politics\")\n",
    "print(len(politicaldiscussion_df), \"total comments from r/PoliticalDiscussion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the test samples for evals\n",
    "# since we trained using 80% of the total comments, we test on 20% of them.\n",
    "\n",
    "import nltk\n",
    "\n",
    "boundary = int(len(news_df)*0.8) #80/20 train/test split\n",
    "news_df_test = news_df[boundary:]\n",
    "\n",
    "boundary = int(len(politics_df)*0.8) #80/20 train/test split\n",
    "politics_df_test = politics_df[boundary:]\n",
    "\n",
    "boundary = int(len(politicaldiscussion_df)*0.8) #80/20 train/test split\n",
    "politicaldiscussion_df_test = politicaldiscussion_df[boundary:]\n",
    "\n",
    "news_test_vocab = nltk.lm.Vocabulary([word for sent in news_df_test['tokens'] for word in sent])\n",
    "politics_test_vocab = nltk.lm.Vocabulary([word for sent in politics_df_test['tokens'] for word in sent])\n",
    "politicaldiscussion_test_vocab = nltk.lm.Vocabulary([word for sent in politicaldiscussion_df_test['tokens'] for word in sent])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokenizer, texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, len(tokenizer.word_index))\n",
    "\n",
    "def generate_char(model, tokenizer, text, temperature=1):\n",
    "    X_new = preprocess(tokenizer, [text])\n",
    "    Y_pred = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled = tf.math.log(Y_pred)/temperature\n",
    "    char_id = tf.random.categorical(rescaled, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "def generate(model, tokenizer, text, n=50, temperature=1):\n",
    "    for _ in range(n):\n",
    "        text += generate_char(model, tokenizer, text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def random_char():\n",
    "    return random.choice(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "\n",
    "random_char()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make tokenizers for each of the models\n",
    "news_all_text = \"\"\n",
    "for comment in news_df['clean']:\n",
    "    news_all_text += \"<\" + comment + \">\"\n",
    "    \n",
    "politics_all_text = \"\"\n",
    "for comment in politics_df['clean']:\n",
    "    politics_all_text += \"<\" + comment + \">\"\n",
    "    \n",
    "political_discussion_all_text = \"\"\n",
    "for comment in politicaldiscussion_df['clean']:\n",
    "    political_discussion_all_text += \"<\" + comment + \">\"\n",
    "    \n",
    "news_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "news_tokenizer.fit_on_texts(news_all_text)\n",
    "\n",
    "politics_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "politics_tokenizer.fit_on_texts(politics_all_text)\n",
    "\n",
    "political_discussion_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "political_discussion_tokenizer.fit_on_texts(political_discussion_all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "news_model = keras.models.load_model('saved_models/NEWS_RNN_2_GRU_128_SOFTMAX_03_DROPOUT_EARLY_STOPPING', compile=False)\n",
    "politics_model = keras.models.load_model('saved_models/POLITICS_RNN_2_GRU_128_SOFTMAX_03_DROPOUT_EARLY_STOPPING', compile=False)\n",
    "political_discussion_model = keras.models.load_model('saved_models/POLDIS_RNN_2_GRU_128_SOFTMAX_03_DROPOUT_EARLY_STOPPING/', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake sentence from r/news:\n",
      " just for the station and the cops were the station in the rich community. the us government is the ri \n",
      "\n",
      "Fake sentence from r/politics:\n",
      " re is the people with a conservative is the person who can do some thing and people with a state stat \n",
      "\n",
      "Fake sentence from r/PoliticalDiscussion:\n",
      " ver the last of the thing of the thing of the market problem in the fact of the thing of the same in  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fake sentence from r/news:\\n\", generate(news_model, news_tokenizer, random_char(), n=100, temperature=0.2),\"\\n\")\n",
    "print(\"Fake sentence from r/politics:\\n\", generate(politics_model, politics_tokenizer, random_char(), n=100, temperature=0.2),\"\\n\")\n",
    "print(\"Fake sentence from r/PoliticalDiscussion:\\n\", generate(political_discussion_model, political_discussion_tokenizer, random_char(), n=100, temperature=0.2),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexities of test vocabularies\n",
      "==============================\n",
      "r/news: 9.158309963881798\n",
      "r/politics: 9.319374133000306\n",
      "r/PoliticalDiscussion: 9.49363784611014\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexities of test vocabularies\")\n",
    "print(\"==============================\")\n",
    "print(\"r/news:\", np.log(len(news_test_vocab)))\n",
    "print(\"r/politics:\", np.log(len(politics_test_vocab)))\n",
    "print(\"r/PoliticalDiscussion:\", np.log(len(politicaldiscussion_test_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexities of models\n",
      "r/news: 5.864985442469667\n",
      "r/politics: 4.437095519003664\n",
      "r/PoliticalDiscussion: 5.528961477624003\n"
     ]
    }
   ],
   "source": [
    "#losses from tensorflow logs\n",
    "news_loss = 1.769\n",
    "politics_loss = 1.49\n",
    "political_discussion_loss = 1.71\n",
    "print(\"Perplexities of models\")\n",
    "(\"==============================\")\n",
    "print(\"r/news:\", np.e ** news_loss)\n",
    "print(\"r/politics:\", np.e ** politics_loss)\n",
    "print(\"r/PoliticalDiscussion:\", np.e ** political_discussion_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d62960500a46ae92dd809e14c4635b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=267844284.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cb474b78674388aa510374fa225f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis\n",
    "\n",
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random selection of 500 sentences from each subreddit\n",
    "#BERT only allows for 512 tokens for embeddings\n",
    "news_sentiments = classifier(list(news_df[news_df['clean'].str.len() < 512]['clean'].sample(500)))\n",
    "politics_sentiments = classifier(list(politics_df[politics_df['clean'].str.len() < 512]['clean'].sample(500)))\n",
    "politicaldiscussion_sentiments = classifier(list(politicaldiscussion_df[politicaldiscussion_df['clean'].str.len() < 512]['clean'].sample(500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_adjusted_sentiments = np.array([result['score'] * 1 if result['label'] == \"POSITIVE\" else result['score'] * -1 for result in news_sentiments])\n",
    "\n",
    "politics_adjusted_sentiments = np.array([result['score'] * 1 if result['label'] == \"POSITIVE\" else result['score'] * -1 for result in politics_sentiments])\n",
    "\n",
    "politicaldiscussion_adjusted_sentiments = np.array([result['score'] * 1 if result['label'] == \"POSITIVE\" else result['score'] * -1 for result in politicaldiscussion_sentiments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_avg_sentiment = news_adjusted_sentiments.mean()\n",
    "politics_avg_sentiment = politics_adjusted_sentiments.mean()\n",
    "politicaldiscussion_sentiment = politicaldiscussion_adjusted_sentiments.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngenerated sentences\n",
    "news_generated = []\n",
    "for i in range(100):\n",
    "    news_generated.append(generate(news_model, news_tokenizer, random_char(), n=100, temperature=0.3))\n",
    "    \n",
    "politics_generated = []\n",
    "for i in range(100):\n",
    "    politics_generated.append(generate(politics_model, politics_tokenizer, random_char(), n=100, temperature=0.3))\n",
    "    \n",
    "political_discussion_generated = []\n",
    "for i in range(100):\n",
    "    political_discussion_generated.append(generate(political_discussion_model, political_discussion_tokenizer, random_char(), n=100, temperature=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_generated_sentiments = classifier(news_generated)\n",
    "news_generated_avg_sentiment = np.array([result['score'] * 1 if result['label'] == \"POSITIVE\" else result['score'] * -1 for result in news_generated_sentiments]).mean()\n",
    "\n",
    "politics_generated = classifier(politics_generated)\n",
    "politics_generated_avg_sentiment = np.array([result['score'] * 1 if result['label'] == \"POSITIVE\" else result['score'] * -1 for result in politics_generated]).mean()\n",
    "\n",
    "political_discussion_generated = classifier(political_discussion_generated)\n",
    "political_discussion_generated_avg_sentiment = np.array([result['score'] * 1 if result['label'] == \"POSITIVE\" else result['score'] * -1 for result in political_discussion_generated]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentiments for Subreddits\n",
      "r/news: -0.5521513446569443\n",
      "r/politics: -0.42779424095153806\n",
      "r/PoliticalDiscussion: -0.534076133608818\n",
      "\n",
      "Is this really surprising?\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Sentiments for Subreddits\")\n",
    "(\"==============================\")\n",
    "print(\"r/news:\", news_avg_sentiment)\n",
    "print(\"r/politics:\", politics_avg_sentiment)\n",
    "print(\"r/PoliticalDiscussion:\", politicaldiscussion_sentiment)\n",
    "print(\"\\nIs this really surprising?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentiments for Generated Sentences\n",
      "r/news: -0.5295556646585464\n",
      "r/politics: -0.4439292925596237\n",
      "r/PoliticalDiscussion: -0.8093147230148315\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Sentiments for Generated Sentences\")\n",
    "(\"==============================\")\n",
    "print(\"r/news:\", news_generated_avg_sentiment)\n",
    "print(\"r/politics:\", politics_generated_avg_sentiment)\n",
    "print(\"r/PoliticalDiscussion:\", political_discussion_generated_avg_sentiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
